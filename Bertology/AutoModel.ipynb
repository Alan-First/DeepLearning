{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- encoding: utf-8 -*-\n",
    "'''\n",
    "@File         :AutoModel.ipynb\n",
    "@Description  :用automodel方式完成多种NLP任务\n",
    "@Time         :2022/04/28 20:40:19\n",
    "@Author       :Hedwig\n",
    "@Version      :1.0\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoModel类用于管理Transformers库中处理相同地NLP任务的底层具体模型，为上层应用管道方式提供统一的接口\n",
    "# 按Bertology系列的应用场景，Transformer库被划分为以下6个子类\n",
    "# AutoModel：基本载入类，适用于Transformers中的任何模型，也适用于特征提取\n",
    "# AutoModelForPreTraining：特征提取任务的模型载入类，适用于Transformers库中所有的预训练模型\n",
    "# AutoModelForSequenceClassification：文本分类的模型载入类，适用于Transformers中所有文本分类模型\n",
    "# AutoModelForQuestionAnswering：阅读理解任务的模型载入类，适用于Transformers中所有抽取式问答模型\n",
    "# AutoModelWithLMHead：完形填空任务的模型载入类，适用于Transformers中所有遮蔽语言模型\n",
    "# AutoModelForTokenClassification：实体词识别的模型载入类，适用于Transformers库中所有实体词识别模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers的models/auto路径下有modeling_auto.py源文件，可以找到模型载入类和具体的模型映射关系\n",
    "# 以AutoModelWithLMHead类为例，MODEL_WITH_LM_HEAD_MAPPING_NAMES代表了载入类与系列模型的映射\n",
    "# 在这里列出的所有元素都可以实现AutoModelWithLMHead类所完成的完形填空\n",
    "# 它的元素包括两部分，具体模型的配置文件和具体模型的实现类\n",
    "# 每一个具体模型的实现类会通过不同数据集被训练成多套预训练模型文件\n",
    "# 每套模型训练文件又由3-4个子文件组成：词表文件、词表扩展文件(可选)、配置文件和模型权值文件\n",
    "# 这些文件共用一个统一的字符串标识\n",
    "# 用自动加载方式调用模型时，系统会根据统一的预训练模型字符串标识，找到对应的预训练模型文件，通过网络下载并载入 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 具体地，pipeline的任务字符串(以fill-mask为例)传入后，pipeline会把传入的任务作为SUPPORTED_TASKS的键，\n",
    "# 找到对应的配置字典，用get_default_model方法根据配置字典中default键找到相应model的模型字符串\n",
    "# (这里是distilroberta-base)，这个字符串用于infer_framework_load_model函数转化为模型的类\n",
    "# 在默认的SUPPORTED_TASKS中就是AutoModelForMaskedLM类 \n",
    "# 同时还会用配置字典的imple键找到子pipeline的类名(这里是FillMaskPipeline，如果pipeline_class有指定就用\n",
    "# 指定的这个)，并调用它的call方法，将模型的类作为参数传入\n",
    "# 模型的类又调用相应的任务，(在这里是RobertaForMaskedLM)，加载相应的配置文件\n",
    "# transformmer文件下的modelcards.py有任务字符串的键(fill-mask)与对应的\n",
    "# (MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING_NAMES)的映射\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
