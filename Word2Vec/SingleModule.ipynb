{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init embed Parameter containing:\n",
      "tensor([[ 1.7509, -0.7933, -0.9278,  0.0388, -0.4009],\n",
      "        [ 1.3134,  3.2451, -0.0717, -1.4094, -0.0504],\n",
      "        [ 0.1722, -0.6872,  0.6585, -0.2432,  0.5528],\n",
      "        [-0.9784,  0.7325,  1.1104,  0.2580,  0.4777]], requires_grad=True)\n",
      "word vector of word1 is tensor([[ 1.7509, -0.7933, -0.9278,  0.0388, -0.4009],\n",
      "        [ 1.3134,  3.2451, -0.0717, -1.4094, -0.0504],\n",
      "        [ 0.1722, -0.6872,  0.6585, -0.2432,  0.5528]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "new embed Parameter containing:\n",
      "tensor([[ 0.0918, -0.0733,  0.1528, -0.2699,  0.4226],\n",
      "        [ 0.4482, -0.0054, -0.1250,  0.4544, -0.2707],\n",
      "        [ 0.1023, -0.0611,  0.3351, -0.2793,  0.2026],\n",
      "        [-0.2983, -0.2673, -0.3272,  0.1086, -0.4682]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#torch.nn.Embedding(n,m)是用于词嵌入的,n是单词数，m是词向量维度数\n",
    "# 创建一个long类型的张量，这是一个索引张量，比如词袋中元素只有四个数\n",
    "# “你好吗我”在词袋中one-hot编码以后分别是0，1，2，3\n",
    "# 那么word1这个列表代表的就是“你好吗”这个含义\n",
    "word1 = torch.LongTensor([0,1,2])\n",
    "word2 = torch.LongTensor([3,1,2])\n",
    "# embedding则是创建一个参数可学习的随机张量矩阵，词袋有4个数，维度就是4，每个词向量维度是5\n",
    "# word1和word2分别用索引的方式获取每个字的词向量\n",
    "embedded = nn.Embedding(4,5)\n",
    "print('init embed',embedded.weight)\n",
    "print('word vector of word1 is',embedded(word1))#size为（3，5），表示3个字\n",
    "embedded.weight.data.uniform_(-0.5,0.5)\n",
    "print('new embed',embedded.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#一个batch的矩阵相乘\n",
    "batch_size = 3\n",
    "embed_size = 5\n",
    "context_num = 4\n",
    "inputs = torch.randn(batch_size,embed_size,1)\n",
    "mats = torch.randn(batch_size,context_num,embed_size)\n",
    "result = torch.bmm(mats,inputs)#batch_matrix_multiply\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "mats = torch.randn(5,8)\n",
    "trans = mats.view(5,1,-1)\n",
    "print(trans.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
